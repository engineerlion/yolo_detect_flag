{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2b6c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Detection_proj/mmdetection\n"
     ]
    }
   ],
   "source": [
    "%cd mmdetection\n",
    "import mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b453d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "model = dict(\n",
      "    type='YOLOV3',\n",
      "    backbone=dict(\n",
      "        type='Darknet',\n",
      "        depth=53,\n",
      "        out_indices=(3, 4, 5),\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='open-mmlab://darknet53')),\n",
      "    neck=dict(\n",
      "        type='YOLOV3Neck',\n",
      "        num_scales=3,\n",
      "        in_channels=[1024, 512, 256],\n",
      "        out_channels=[512, 256, 128]),\n",
      "    bbox_head=dict(\n",
      "        type='YOLOV3Head',\n",
      "        num_classes=80,\n",
      "        in_channels=[512, 256, 128],\n",
      "        out_channels=[1024, 512, 256],\n",
      "        anchor_generator=dict(\n",
      "            type='YOLOAnchorGenerator',\n",
      "            base_sizes=[[(116, 90), (156, 198), (373, 326)],\n",
      "                        [(30, 61), (62, 45), (59, 119)],\n",
      "                        [(10, 13), (16, 30), (33, 23)]],\n",
      "            strides=[32, 16, 8]),\n",
      "        bbox_coder=dict(type='YOLOBBoxCoder'),\n",
      "        featmap_strides=[32, 16, 8],\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=True,\n",
      "            loss_weight=1.0,\n",
      "            reduction='sum'),\n",
      "        loss_conf=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=True,\n",
      "            loss_weight=1.0,\n",
      "            reduction='sum'),\n",
      "        loss_xy=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=True,\n",
      "            loss_weight=2.0,\n",
      "            reduction='sum'),\n",
      "        loss_wh=dict(type='MSELoss', loss_weight=2.0, reduction='sum')),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(\n",
      "            type='GridAssigner',\n",
      "            pos_iou_thr=0.5,\n",
      "            neg_iou_thr=0.5,\n",
      "            min_pos_iou=0)),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.05,\n",
      "        conf_thr=0.005,\n",
      "        nms=dict(type='nms', iou_threshold=0.45),\n",
      "        max_per_img=100))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(mean=[0, 0, 0], std=[255.0, 255.0, 255.0], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='Expand', mean=[0, 0, 0], to_rgb=True, ratio_range=(1, 2)),\n",
      "    dict(\n",
      "        type='MinIoURandomCrop',\n",
      "        min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
      "        min_crop_size=0.3),\n",
      "    dict(type='Resize', img_scale=[(320, 320), (416, 416)], keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[0, 0, 0],\n",
      "        std=[255.0, 255.0, 255.0],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(416, 416),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[0, 0, 0],\n",
      "                std=[255.0, 255.0, 255.0],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_train2017.json',\n",
      "        img_prefix='data/coco/train2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='Expand', mean=[0, 0, 0], to_rgb=True,\n",
      "                ratio_range=(1, 2)),\n",
      "            dict(\n",
      "                type='MinIoURandomCrop',\n",
      "                min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
      "                min_crop_size=0.3),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=[(320, 320), (416, 416)],\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[0, 0, 0],\n",
      "                std=[255.0, 255.0, 255.0],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(416, 416),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[255.0, 255.0, 255.0],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(416, 416),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[255.0, 255.0, 255.0],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=2000,\n",
      "    warmup_ratio=0.1,\n",
      "    step=[218, 246])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=273)\n",
      "evaluation = dict(interval=1, metric=['bbox'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import set_random_seed\n",
    "from mmcv import Config\n",
    "from pprint import pprint\n",
    "#cfg = Config.fromfile('./configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py')\n",
    "#faster_rcnn_r50_caffe_fpn_1x_coco_bbox_mAP-0.378_20200504_180032-c5925ee5.pth\n",
    "cfg = Config.fromfile('./configs/yolo/yolov3_d53_mstrain-416_273e_coco.py')\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8469035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/yolov3_d53_mstrain-416_273e_coco-2b60fcd9.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "model = dict(\n",
      "    type='YOLOV3',\n",
      "    backbone=dict(\n",
      "        type='Darknet',\n",
      "        depth=53,\n",
      "        out_indices=(3, 4, 5),\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='open-mmlab://darknet53')),\n",
      "    neck=dict(\n",
      "        type='YOLOV3Neck',\n",
      "        num_scales=3,\n",
      "        in_channels=[1024, 512, 256],\n",
      "        out_channels=[512, 256, 128]),\n",
      "    bbox_head=dict(\n",
      "        type='YOLOV3Head',\n",
      "        num_classes=11,\n",
      "        in_channels=[512, 256, 128],\n",
      "        out_channels=[1024, 512, 256],\n",
      "        anchor_generator=dict(\n",
      "            type='YOLOAnchorGenerator',\n",
      "            base_sizes=[[(116, 90), (156, 198), (373, 326)],\n",
      "                        [(30, 61), (62, 45), (59, 119)],\n",
      "                        [(10, 13), (16, 30), (33, 23)]],\n",
      "            strides=[32, 16, 8]),\n",
      "        bbox_coder=dict(type='YOLOBBoxCoder'),\n",
      "        featmap_strides=[32, 16, 8],\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=True,\n",
      "            loss_weight=1.0,\n",
      "            reduction='sum'),\n",
      "        loss_conf=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=True,\n",
      "            loss_weight=1.0,\n",
      "            reduction='sum'),\n",
      "        loss_xy=dict(\n",
      "            type='CrossEntropyLoss',\n",
      "            use_sigmoid=True,\n",
      "            loss_weight=2.0,\n",
      "            reduction='sum'),\n",
      "        loss_wh=dict(type='MSELoss', loss_weight=2.0, reduction='sum')),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(\n",
      "            type='GridAssigner',\n",
      "            pos_iou_thr=0.5,\n",
      "            neg_iou_thr=0.5,\n",
      "            min_pos_iou=0)),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.05,\n",
      "        conf_thr=0.005,\n",
      "        nms=dict(type='nms', iou_threshold=0.45),\n",
      "        max_per_img=100))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = '/data/flag/Images'\n",
      "img_norm_cfg = dict(mean=[0, 0, 0], std=[255.0, 255.0, 255.0], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile', to_float32=True),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='Expand', mean=[0, 0, 0], to_rgb=True, ratio_range=(1, 2)),\n",
      "    dict(\n",
      "        type='MinIoURandomCrop',\n",
      "        min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
      "        min_crop_size=0.3),\n",
      "    dict(type='Resize', img_scale=[(320, 320), (416, 416)], keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[0, 0, 0],\n",
      "        std=[255.0, 255.0, 255.0],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(416, 416),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[0, 0, 0],\n",
      "                std=[255.0, 255.0, 255.0],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/data/flag/flag_coco_train.json',\n",
      "        img_prefix='/data/flag/Images',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='Expand', mean=[0, 0, 0], to_rgb=True,\n",
      "                ratio_range=(1, 2)),\n",
      "            dict(\n",
      "                type='MinIoURandomCrop',\n",
      "                min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n",
      "                min_crop_size=0.3),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=[(320, 320), (416, 416)],\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[0, 0, 0],\n",
      "                std=[255.0, 255.0, 255.0],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        classes=[\n",
      "            'china', 'us', 'uk', 'russia', 'japan', 'france', 'german',\n",
      "            'italy', 'australia', 'korea', 'other'\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/data/flag/flag_coco_val.json',\n",
      "        img_prefix='/data/flag/Images',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(416, 416),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[255.0, 255.0, 255.0],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=[\n",
      "            'china', 'us', 'uk', 'russia', 'japan', 'france', 'german',\n",
      "            'italy', 'australia', 'korea', 'other'\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/data/flag/flag_coco_test.json',\n",
      "        img_prefix='/data/flag/Images',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(416, 416),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[255.0, 255.0, 255.0],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        classes=[\n",
      "            'china', 'us', 'uk', 'russia', 'japan', 'france', 'german',\n",
      "            'italy', 'australia', 'korea', 'other'\n",
      "        ]))\n",
      "optimizer = dict(type='SGD', lr=0.00025, momentum=0.9, weight_decay=0.0005)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=2000,\n",
      "    warmup_ratio=0.1,\n",
      "    step=[218, 246])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=273)\n",
      "evaluation = dict(interval=1, metric=['bbox'])\n",
      "classes = [\n",
      "    'china', 'us', 'uk', 'russia', 'japan', 'france', 'german', 'italy',\n",
      "    'australia', 'korea', 'other'\n",
      "]\n",
      "work_dir = './flag_proj/yolov3'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "CLASS = ['china','us','uk','russia','japan','france','german','italy','australia','korea','other']\n",
    "                \n",
    "# Modify dataset type and path\n",
    "cfg.data_root = '/data/flag/Images'\n",
    "cfg.classes = CLASS\n",
    "\n",
    "cfg.data.samples_per_gpu = 2\n",
    "cfg.data.workers_per_gpu = 4\n",
    "\n",
    "cfg.data.test.img_prefix = '/data/flag/Images'\n",
    "cfg.data.test.ann_file = '/data/flag/flag_coco_test.json'\n",
    "cfg.data.test.classes = CLASS\n",
    "\n",
    "cfg.data.train.ann_file = '/data/flag/flag_coco_train.json'\n",
    "cfg.data.train.img_prefix = '/data/flag/Images'\n",
    "cfg.data.train.classes = CLASS\n",
    "\n",
    "cfg.data.val.img_prefix = '/data/flag/Images'\n",
    "cfg.data.val.ann_file = '/data/flag/flag_coco_val.json'\n",
    "cfg.data.val.classes = CLASS\n",
    "\n",
    "# modify num classes of the model in box head\n",
    "cfg.model.bbox_head.num_classes = 11\n",
    "#cfg.model.roi_head.mask_head.num_classes = 1\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch\n",
    "#cfg.load_from = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_\\\n",
    "#coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
    "cfg.load_from = 'checkpoints/yolov3_d53_mstrain-416_273e_coco-2b60fcd9.pth'\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './flag_proj/yolov3'\n",
    "\n",
    "if not os.path.exists(cfg.work_dir):\n",
    "    os.makedirs(cfg.work_dir)\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer.lr = 0.001 / 4\n",
    "#cfg.lr_config.warmup = None\n",
    "#log interval by step not epoch\n",
    "cfg.log_config.interval = 100\n",
    "\n",
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = ['bbox']\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.evaluation.interval = 1\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 1\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "#cfg.workflow = [('train',1),('val',1)]\n",
    "\n",
    "#cfg.runner.max_epochs = 1\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n",
    "cfg.dump(osp.join(cfg.work_dir, 'flag_config.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd47c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Detection_proj/mmdetection/mmdet/core/anchor/builder.py:16: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
      "  '``build_anchor_generator`` would be deprecated soon, please use '\n"
     ]
    }
   ],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "import os.path as osp\n",
    "import copy\n",
    "\n",
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "if len(cfg.workflow) == 2:\n",
    "    val_dataset = copy.deepcopy(cfg.data.val)\n",
    "    val_dataset.pipeline = cfg.train_pipeline\n",
    "    datasets.append(build_dataset(val_dataset))\n",
    "# Build the detector\n",
    "model = build_detector(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ab2b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['china',\n",
       " 'us',\n",
       " 'uk',\n",
       " 'russia',\n",
       " 'japan',\n",
       " 'france',\n",
       " 'german',\n",
       " 'italy',\n",
       " 'australia',\n",
       " 'korea',\n",
       " 'other']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b6703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 17:01:36,578 - mmdet - INFO - load checkpoint from checkpoints/yolov3_d53_mstrain-416_273e_coco-2b60fcd9.pth\n",
      "2021-07-06 17:01:36,579 - mmdet - INFO - Use load_from_local loader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 17:01:36,847 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for bbox_head.convs_pred.0.weight: copying a param with shape torch.Size([255, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 1024, 1, 1]).\n",
      "size mismatch for bbox_head.convs_pred.0.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for bbox_head.convs_pred.1.weight: copying a param with shape torch.Size([255, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 512, 1, 1]).\n",
      "size mismatch for bbox_head.convs_pred.1.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "size mismatch for bbox_head.convs_pred.2.weight: copying a param with shape torch.Size([255, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([48, 256, 1, 1]).\n",
      "size mismatch for bbox_head.convs_pred.2.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([48]).\n",
      "2021-07-06 17:01:36,863 - mmdet - INFO - Start running, host: root@VM-116-54-centos, work_dir: /data/Detection_proj/mmdetection/flag_proj/yolov3\n",
      "2021-07-06 17:01:36,864 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) EvalHook                           \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2021-07-06 17:01:36,865 - mmdet - INFO - workflow: [('train', 1)], max: 273 epochs\n",
      "/data/Detection_proj/mmdetection/mmdet/core/anchor/anchor_generator.py:323: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/data/Detection_proj/mmdetection/mmdet/core/anchor/anchor_generator.py:360: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  '``single_level_grid_anchors`` would be deprecated soon. '\n",
      "2021-07-06 17:02:04,766 - mmdet - INFO - Epoch [1][100/1264]\tlr: 3.614e-05, eta: 1 day, 2:42:45, time: 0.279, data_time: 0.025, memory: 1522, loss_cls: 53.2823, loss_conf: 5309.6421, loss_xy: 19.8188, loss_wh: 15.8623, loss: 5398.6055, grad_norm: 11716.7332\n",
      "2021-07-06 17:02:29,393 - mmdet - INFO - Epoch [1][200/1264]\tlr: 4.739e-05, eta: 1 day, 1:08:52, time: 0.246, data_time: 0.002, memory: 1522, loss_cls: 54.3492, loss_conf: 568.9744, loss_xy: 19.9410, loss_wh: 10.2285, loss: 653.4931, grad_norm: 1607.3993\n",
      "2021-07-06 17:02:54,095 - mmdet - INFO - Epoch [1][300/1264]\tlr: 5.864e-05, eta: 1 day, 0:38:45, time: 0.247, data_time: 0.003, memory: 1522, loss_cls: 52.3095, loss_conf: 111.1620, loss_xy: 21.4109, loss_wh: 6.4109, loss: 191.2933, grad_norm: 614.0934\n",
      "2021-07-06 17:03:18,721 - mmdet - INFO - Epoch [1][400/1264]\tlr: 6.989e-05, eta: 1 day, 0:22:24, time: 0.246, data_time: 0.002, memory: 1522, loss_cls: 41.9832, loss_conf: 64.2903, loss_xy: 21.0190, loss_wh: 5.0893, loss: 132.3818, grad_norm: 506.3690\n",
      "2021-07-06 17:03:43,926 - mmdet - INFO - Epoch [1][500/1264]\tlr: 8.114e-05, eta: 1 day, 0:19:04, time: 0.252, data_time: 0.002, memory: 1522, loss_cls: 41.6051, loss_conf: 56.2590, loss_xy: 23.2397, loss_wh: 5.1454, loss: 126.2492, grad_norm: 537.4092\n",
      "2021-07-06 17:04:08,595 - mmdet - INFO - Epoch [1][600/1264]\tlr: 9.239e-05, eta: 1 day, 0:11:34, time: 0.247, data_time: 0.002, memory: 1522, loss_cls: 24.2137, loss_conf: 35.6302, loss_xy: 17.6492, loss_wh: 3.1712, loss: 80.6644, grad_norm: 421.8227\n"
     ]
    }
   ],
   "source": [
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac6881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:map] *",
   "language": "python",
   "name": "conda-env-map-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
